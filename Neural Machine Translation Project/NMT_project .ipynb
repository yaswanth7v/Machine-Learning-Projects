{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "gG9kJVRFs0VD"
      },
      "outputs": [],
      "source": [
        "#import dependencies for defining the model\n",
        "import string\n",
        "import re\n",
        "from numpy import array, argmax, random, take\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Embedding, RepeatVector\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import load_model\n",
        "from keras import optimizers\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "K7yP-8k0s-iv"
      },
      "outputs": [],
      "source": [
        "data_path = 'fra.txt'\n",
        "with open(data_path, 'r', encoding='utf-8') as f:\n",
        "  lines = f.read()\n",
        "lines"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def to_lines(text):\n",
        "  sents = text.strip().split('\\n')\n",
        "  sents = [i.split('\\t') for i in sents]\n",
        "  return sents"
      ],
      "metadata": {
        "id": "JUiXbpgk3Uri"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "0sSQ2ixgtB6D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e291878-c40f-444a-fc6c-d53a3e86a326"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Go.',\n",
              "  'Va !',\n",
              "  'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #1158250 (Wittydev)'],\n",
              " ['Go.',\n",
              "  'Marche.',\n",
              "  'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8090732 (Micsmithel)'],\n",
              " ['Go.',\n",
              "  'En route !',\n",
              "  'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8267435 (felix63)'],\n",
              " ['Go.',\n",
              "  'Bouge !',\n",
              "  'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #9022935 (Micsmithel)'],\n",
              " ['Hi.',\n",
              "  'Salut !',\n",
              "  'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #509819 (Aiji)']]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "fra_eng = to_lines(lines)\n",
        "fra_eng[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wA_dDE8NtIAt",
        "outputId": "990725bf-c211-4f8c-9650-e795c0d25739"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['Go.', 'Va !',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #1158250 (Wittydev)'],\n",
              "       ['Go.', 'Marche.',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8090732 (Micsmithel)'],\n",
              "       ['Go.', 'En route !',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8267435 (felix63)'],\n",
              "       ['Go.', 'Bouge !',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #9022935 (Micsmithel)'],\n",
              "       ['Hi.', 'Salut !',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #509819 (Aiji)']],\n",
              "      dtype='<U349')"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "fra_eng = array(fra_eng)\n",
        "fra_eng[:5]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3CUVM2itNZw",
        "outputId": "01da28ed-7c8d-4bc2-bacb-19e6ca08194e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(227815, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "fra_eng.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fra_eng = fra_eng[:150000,:]\n",
        "fra_eng = fra_eng[:,[0,1]]"
      ],
      "metadata": {
        "id": "2Kos_hnN4cu7"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9Ig_wBltQMg",
        "outputId": "7532c059-1823-4a08-b074-20d9c331c588"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['Go', 'Va '],\n",
              "       ['Go', 'Marche'],\n",
              "       ['Go', 'En route '],\n",
              "       ['Go', 'Bouge '],\n",
              "       ['Hi', 'Salut ']], dtype='<U349')"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "# Removing punctuations\n",
        "fra_eng[:,0] = [s.translate(str.maketrans('', '', string.punctuation)) for s in fra_eng[:,0]]\n",
        "fra_eng[:,1] = [s.translate(str.maketrans('', '', string.punctuation)) for s in fra_eng[:,1]]\n",
        "fra_eng[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "G_6Hu_Ih4qQM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee0fbfbb-2af6-4aa9-9926-68ecde8029b4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['go', 'va '],\n",
              "       ['go', 'marche'],\n",
              "       ['go', 'en route '],\n",
              "       ...,\n",
              "       ['i have a daughter in high school', 'jai une fille au lycÃ©e'],\n",
              "       ['i have a few tricks up my sleeve',\n",
              "        'jai plus dun tour dans mon sac'],\n",
              "       ['i have a firstaid kit in my car',\n",
              "        'jai une trousse de premiers soins dans ma voiture']],\n",
              "      dtype='<U349')"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "for i in range(len(fra_eng)):\n",
        "  fra_eng[i,0] = fra_eng[i,0].lower()\n",
        "  fra_eng[i,1] = fra_eng[i,1].lower()\n",
        "fra_eng"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYlBVwjmtUbw",
        "outputId": "6212f221-19a5-43a4-b8ff-49d780b8f1e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English vocabulary size 11320\n"
          ]
        }
      ],
      "source": [
        "# function to build tokenizer\n",
        "def tokenization(lines):\n",
        "  tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(lines)\n",
        "  return tokenizer\n",
        "\n",
        "# english tokenizer\n",
        "eng_tokenizer = tokenization(fra_eng[:, 0])\n",
        "eng_vocab_size = len(eng_tokenizer.word_index)+1\n",
        "\n",
        "eng_length = 8\n",
        "print(f\"English vocabulary size {eng_vocab_size}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XBxjvvf9b5eM"
      },
      "outputs": [],
      "source": [
        "eng_tokenizer.word_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "Xd-R9mwFUs51"
      },
      "outputs": [],
      "source": [
        "for word, index in eng_tokenizer.word_index.items():\n",
        "  if index==0:\n",
        "    print(word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPfDND7Vt87w",
        "outputId": "5b2d0b8d-0f47-4b7b-dc77-6a6a5a8c08a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "French vocabulary size 26738\n"
          ]
        }
      ],
      "source": [
        "# french tokenizer\n",
        "fra_tokenizer = tokenization(fra_eng[:, 1])\n",
        "fra_vocab_size = len(fra_tokenizer.word_index)+1\n",
        "\n",
        "fra_length = 8\n",
        "print(f\"French vocabulary size {fra_vocab_size}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "cktye4EnuAJv"
      },
      "outputs": [],
      "source": [
        "# encode and pad sequences,padding to a maximum sentence length as mentioned\n",
        "def encode_sequences(tokenizer, length, lines):\n",
        "  # integer encode sequences\n",
        "  sequence = tokenizer.texts_to_sequences(lines)\n",
        "  #pad sequences with 0 values\n",
        "  sequence = pad_sequences(sequence, maxlen=length)\n",
        "  return sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "f_nlbLvmxz3a"
      },
      "outputs": [],
      "source": [
        "# splitting the data into training and testing\n",
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(fra_eng, test_size=0.2, random_state = 12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "qa6PuNPex90C"
      },
      "outputs": [],
      "source": [
        "# prepare train data\n",
        "trainX = encode_sequences(fra_tokenizer, fra_length, train[:,1])\n",
        "trainY = encode_sequences(eng_tokenizer, eng_length, train[:,0])\n",
        "\n",
        "# prepare test data\n",
        "testX = encode_sequences(fra_tokenizer, fra_length, test[:,1])\n",
        "testY = encode_sequences(eng_tokenizer, eng_length, test[:,0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKcTvAyA1eL5",
        "outputId": "170903a2-5ddf-42f3-ccdf-12ea73f27bca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((120000, 8), (1000, 8))"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "testX = testX[:1000, :]\n",
        "trainX.shape, testX.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "uj4NwZzTA3kE"
      },
      "outputs": [],
      "source": [
        "# Define the model\n",
        "def define_model(in_vocab, out_vocab, in_timesteps, out_timesteps, units):\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(in_vocab, units, input_length=in_timesteps, mask_zero=True))\n",
        "  model.add(LSTM(units))\n",
        "  model.add(RepeatVector(out_timesteps))\n",
        "  model.add(LSTM(units, return_sequences=True))\n",
        "  model.add(Dense(out_vocab, activation='softmax'))\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "mQjVmSSvzPHN"
      },
      "outputs": [],
      "source": [
        "# model compilation\n",
        "model = define_model(fra_vocab_size, eng_vocab_size, fra_length, eng_length, 512)\n",
        "adam = optimizers.Adam(learning_rate=0.01)\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUu6rVjeCvod",
        "outputId": "daa2e25f-a622-42c1-b537-359e1f5f50b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 8, 512)            13689856  \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (None, 512)               2099200   \n",
            "                                                                 \n",
            " repeat_vector_2 (RepeatVec  (None, 8, 512)            0         \n",
            " tor)                                                            \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 8, 512)            2099200   \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 8, 11320)          5807160   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23695416 (90.39 MB)\n",
            "Trainable params: 23695416 (90.39 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "wYspKFHH1DtJ"
      },
      "outputs": [],
      "source": [
        "#initialize the callback for early stopping the training if there is not atleast 1% improvement in the accuracy\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "es = EarlyStopping(monitor = 'accuracy', min_delta=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Md4dYI8u1Xgt",
        "outputId": "2df4835c-b1d8-4c51-fe3b-1a328411d592"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((120000, 8), (120000, 8))"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "trainX.shape, trainY.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_bZ2-ruQQ_7",
        "outputId": "e3efca7c-3cd9-4d7f-be65-c9ec17411264"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(120000, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "trainY.reshape(trainY.shape[0], trainY.shape[1], 1)\n",
        "trainY.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train model\n",
        "history=model.fit(trainX, trainY,\n",
        "                  epochs=50, batch_size=512, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUZ2mN4VtpT5",
        "outputId": "756a38f8-db33-4f51-d884-aa9f193e8709"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "188/188 [==============================] - 37s 167ms/step - loss: 4.7618 - acc: 0.3955 - val_loss: 4.6620 - val_acc: 0.4007\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 25s 132ms/step - loss: 4.4951 - acc: 0.4001 - val_loss: 4.3817 - val_acc: 0.4126\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 24s 126ms/step - loss: 4.1725 - acc: 0.4136 - val_loss: 3.9912 - val_acc: 0.4215\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 24s 126ms/step - loss: 3.7311 - acc: 0.4351 - val_loss: 3.5594 - val_acc: 0.4448\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 3.3094 - acc: 0.4638 - val_loss: 3.2005 - val_acc: 0.4726\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 23s 122ms/step - loss: 2.9470 - acc: 0.4931 - val_loss: 2.9461 - val_acc: 0.4955\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 2.6655 - acc: 0.5196 - val_loss: 2.7380 - val_acc: 0.5145\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 23s 123ms/step - loss: 2.4178 - acc: 0.5449 - val_loss: 2.5629 - val_acc: 0.5353\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 23s 125ms/step - loss: 2.2060 - acc: 0.5674 - val_loss: 2.4456 - val_acc: 0.5504\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 23s 125ms/step - loss: 2.0368 - acc: 0.5863 - val_loss: 2.3524 - val_acc: 0.5639\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 23s 123ms/step - loss: 1.8928 - acc: 0.6039 - val_loss: 2.2849 - val_acc: 0.5720\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 24s 126ms/step - loss: 1.7691 - acc: 0.6194 - val_loss: 2.2157 - val_acc: 0.5816\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 23s 125ms/step - loss: 1.6696 - acc: 0.6322 - val_loss: 2.1811 - val_acc: 0.5856\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 24s 126ms/step - loss: 1.5843 - acc: 0.6442 - val_loss: 2.1521 - val_acc: 0.5907\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 23s 125ms/step - loss: 1.5030 - acc: 0.6569 - val_loss: 2.1278 - val_acc: 0.5977\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 23s 122ms/step - loss: 1.4402 - acc: 0.6668 - val_loss: 2.1230 - val_acc: 0.6018\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 23s 121ms/step - loss: 1.3826 - acc: 0.6765 - val_loss: 2.1018 - val_acc: 0.6031\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 23s 122ms/step - loss: 1.3347 - acc: 0.6840 - val_loss: 2.0861 - val_acc: 0.6083\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 23s 123ms/step - loss: 1.2896 - acc: 0.6919 - val_loss: 2.0894 - val_acc: 0.6079\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 1.2511 - acc: 0.6982 - val_loss: 2.0926 - val_acc: 0.6080\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 23s 123ms/step - loss: 1.2200 - acc: 0.7035 - val_loss: 2.0913 - val_acc: 0.6141\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 23s 123ms/step - loss: 1.1915 - acc: 0.7092 - val_loss: 2.0973 - val_acc: 0.6133\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 23s 123ms/step - loss: 1.1683 - acc: 0.7126 - val_loss: 2.1039 - val_acc: 0.6098\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 1.1428 - acc: 0.7170 - val_loss: 2.1007 - val_acc: 0.6168\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 23s 121ms/step - loss: 1.1154 - acc: 0.7221 - val_loss: 2.1031 - val_acc: 0.6169\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 23s 122ms/step - loss: 1.0962 - acc: 0.7253 - val_loss: 2.1147 - val_acc: 0.6192\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 23s 123ms/step - loss: 1.0759 - acc: 0.7297 - val_loss: 2.1171 - val_acc: 0.6214\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 1.0559 - acc: 0.7338 - val_loss: 2.1281 - val_acc: 0.6201\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 23s 123ms/step - loss: 1.0417 - acc: 0.7360 - val_loss: 2.1416 - val_acc: 0.6223\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 23s 123ms/step - loss: 1.0317 - acc: 0.7373 - val_loss: 2.1380 - val_acc: 0.6221\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 1.0159 - acc: 0.7409 - val_loss: 2.1592 - val_acc: 0.6204\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 1.0046 - acc: 0.7423 - val_loss: 2.1506 - val_acc: 0.6211\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 0.9937 - acc: 0.7448 - val_loss: 2.1636 - val_acc: 0.6230\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 0.9784 - acc: 0.7482 - val_loss: 2.1714 - val_acc: 0.6233\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 23s 122ms/step - loss: 0.9693 - acc: 0.7494 - val_loss: 2.1650 - val_acc: 0.6235\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 23s 122ms/step - loss: 0.9610 - acc: 0.7515 - val_loss: 2.1814 - val_acc: 0.6209\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 23s 123ms/step - loss: 0.9526 - acc: 0.7520 - val_loss: 2.1882 - val_acc: 0.6240\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 23s 122ms/step - loss: 0.9408 - acc: 0.7546 - val_loss: 2.1878 - val_acc: 0.6260\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 0.9309 - acc: 0.7564 - val_loss: 2.2068 - val_acc: 0.6236\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 23s 123ms/step - loss: 0.9277 - acc: 0.7572 - val_loss: 2.2054 - val_acc: 0.6254\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 23s 122ms/step - loss: 0.9205 - acc: 0.7588 - val_loss: 2.2325 - val_acc: 0.6269\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 24s 126ms/step - loss: 0.9161 - acc: 0.7599 - val_loss: 2.2266 - val_acc: 0.6264\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 23s 123ms/step - loss: 0.9085 - acc: 0.7614 - val_loss: 2.2336 - val_acc: 0.6261\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 23s 121ms/step - loss: 0.8981 - acc: 0.7634 - val_loss: 2.2385 - val_acc: 0.6264\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 23s 122ms/step - loss: 0.8876 - acc: 0.7653 - val_loss: 2.2499 - val_acc: 0.6256\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 23s 123ms/step - loss: 0.8840 - acc: 0.7663 - val_loss: 2.2649 - val_acc: 0.6254\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 23s 123ms/step - loss: 0.8739 - acc: 0.7681 - val_loss: 2.2674 - val_acc: 0.6249\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 23s 122ms/step - loss: 0.8696 - acc: 0.7690 - val_loss: 2.2824 - val_acc: 0.6256\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 23s 123ms/step - loss: 0.8621 - acc: 0.7706 - val_loss: 2.2841 - val_acc: 0.6236\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 23s 123ms/step - loss: 0.8537 - acc: 0.7723 - val_loss: 2.2873 - val_acc: 0.6273\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "qYBbmSXO05bF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc664b3f-a15b-4d30-f7d7-764e5ac7d9bd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1000, 8), (1000, 8))"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "t = testX.shape\n",
        "testX.reshape((testX.shape[0], testX.shape[1]))\n",
        "testX.shape, t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "72v4G6Ju4g9w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4daf8d49-bcc1-4648-afbf-821e9f02cd4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 2s 7ms/step\n"
          ]
        }
      ],
      "source": [
        "predictions = model.predict(testX[:1000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "wAd5dzsPEKI2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4563f93f-4be3-4d16-c4a9-010b7748b645"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.99696374e-01, 3.00583633e-04, 6.60263288e-10, ...,\n",
              "        1.10905417e-19, 8.90215588e-20, 6.28511216e-19],\n",
              "       [9.74016607e-01, 2.53636204e-02, 1.09170169e-05, ...,\n",
              "        5.01354912e-20, 8.94420057e-20, 5.11405189e-20],\n",
              "       [1.47429064e-01, 8.31606627e-01, 2.02211668e-03, ...,\n",
              "        7.21006498e-23, 4.36860920e-22, 6.37209659e-21],\n",
              "       ...,\n",
              "       [5.26983104e-06, 1.25346519e-02, 5.96789760e-04, ...,\n",
              "        3.41173355e-22, 1.97199323e-22, 6.12691660e-24],\n",
              "       [4.42881110e-08, 5.94114303e-04, 4.32074239e-06, ...,\n",
              "        4.97127587e-19, 1.50087313e-22, 3.09994505e-23],\n",
              "       [1.70968573e-08, 1.18704465e-05, 4.36898017e-06, ...,\n",
              "        1.86142571e-16, 9.70327707e-20, 6.20276690e-21]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "predictions[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "YOOHxa3ivvrv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f181aef8-ae3b-4724-daee-765150e2b3fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[9.7401661e-01 2.5363620e-02 1.0917017e-05 ... 5.0135491e-20 8.9442006e-20\n",
            " 5.1140519e-20]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(predictions[0][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "XQp0aIS_vxzE"
      },
      "outputs": [],
      "source": [
        "# function to return the key word for the value\n",
        "def get_word(n, tokenizer):\n",
        "  for word, index in tokenizer.word_index.items():\n",
        "    if (index==n):\n",
        "      print(word)\n",
        "      return word\n",
        "  return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDm3mNa0ftgK"
      },
      "outputs": [],
      "source": [
        "\n",
        "preds_text = []\n",
        "for y in predictions:\n",
        "  temp = []\n",
        "  for word in y:\n",
        "    word = np.array(word)\n",
        "    max_ = max(word)\n",
        "    print(max_)\n",
        "    print(word[0], word[1])\n",
        "    for j in range(len(word)):\n",
        "      if j>0:\n",
        "        if max_ == word[j]:\n",
        "          print(max_, word[j], j)\n",
        "          t = get_word(j, eng_tokenizer)\n",
        "          if t==None:\n",
        "            temp.append('')\n",
        "            #break\n",
        "          else:\n",
        "            temp.append(t)\n",
        "            #break\n",
        "\n",
        "  preds_text.append(' '.join(temp))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test[5,0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7QRGeEF_FGo",
        "outputId": "3dfece0c-e267-4a3d-fd1f-16d2cb217be4"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "do you have a shoehorn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_text[5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "G4b7O4kO_frz",
        "outputId": "529305d0-9a4d-4068-e5a9-7d5ebe2491a3"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'do you have a shoehorn'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}